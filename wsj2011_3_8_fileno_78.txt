Back in the 1940s, the early IT pioneer Claude Shannon fell in love with a computer called Betty, and no one raised an eyebrow. At the time, "computer" was simply the term for a person who performed routine calculations for technical or scientific purposes. Seventy years later, digital processors do all that work and more, and the only "human computers" are mathematical whizzes who can occasionally match the digital processors' feats. "We imitate our old imitators," writes Brian Christian in his absorbing "The Most Human Human." 

The exchanging of roles between human and machine is at the heart of Mr. Christian's project, which weaves its narrative around the Loebner Prize, awarded annually to the world's "most human" computer. The competition is a version of the famous Turing Test, proposed by the British mathematician Alan Turing as a real-world trial of artificial machine intelligence: If a panel of human judges cannot distinguish the responses of a machine from those of a human being, the machine should be deemed to be intelligent.

Mr. Christian entered the 2009 Loebner contest in Brighton, England, not with a computer that he had programmed but as a "confederate": one of the people that the judges have to try to distinguish from the machines. The contest's computer winner comes away with the title "Most Human Computer" (though no computer, as yet, has passed the Turing Test). But the confederates also compete to be named "most human human." By exploring what responses seem "most human," Mr. Christian cleverly suggests that the Turing Test not only tells us how smart computers are but also teaches us about ourselves. 

Take the case of computer chess. Mr. Christian approvingly quotes Douglas Hofstadter, who wrote that "once some mental function is programmed, people cease to consider it as an essential ingredient of 'real thinking.' " Unfortunately for Mr. Hofstadter, he said this in the same book—the Pulitzer Prize-winning "Gödel, Escher, Bach" (1979)—in which he extolled the unique virtues of chess. "Profoundly insightful chess-playing draws intrinsically on central facets of the human condition," he wrote, and a computer's "mere brute force" would never allow it to play at the highest level. So what did Mr. Hofstadter tell the New York Times when IBM's Deep Blue computer beat grand master Garry Kasparov in 1997? "My God, I used to think chess required thought. Now I realize it doesn't."

For Mr. Christian, the right response to Deep Blue's victory is neither defeatism nor redefining thought to make ourselves feel better. Rather we should look at why humans lost and learn from that. In chess, computers are strongest in the parts of the game in which human players rely most on memory: the opening and closing sequences. (Serious players learn strategies by rote, and the early stages of even grandmaster games contain few surprises for the cognoscenti.) Knowledge of these tried and tested moves is called "the book." By the middle section of a game, however, the number of permutations of moves is too vast for memorization to help. Here players need to get "out of book" and act unexpectedly, which is why computers—even Deep Blue—can struggle.

 By Brian Christian  Doubleday, 303 pages, $27.95

Mr. Christian elaborates on this distinction and applies it to human intelligence in general. For isn't it precisely when people refuse to get "out of book"—just following orders or playing their role—that we find them least human? Likewise, when we get "out of book," we are at our most human. Think of the difference between the waiter who runs through the usual routine and the one who responds to your order with a witticism. Remaining alive to what is mechanical or original in our own behavior can preserve a sense of human difference. 

Mr. Christian covers all the major advances in the history of artificial intelligence in a similar way, drawing lessons for how human intelligence works. One recurring theme is how computers must simplify, by converting information to digital bits and then compressing data. Our brains do this too, of course, converting experience into neural patterns and retaining only what is salient. But for all the power of the analogy between the mind and computer software, machines struggle with the incredibly subtle connections we make through richness of context, allusion and ambiguity. Computers prefer information that depends minimally on the precise context in which it is communicated. Thus one way that Mr. Christian found to seem "more human" during the competition was to provide answers with an excess of context. 

Mr. Christian covers a great deal of ground with admirable clarity but with a lightness of touch, and he never tries too hard. He also has a real knack for summing up key ideas by applying them to real-life situations: "If we really want to start fathoming someone," he suggests, "we need to get them speaking in sentences we can't finish."

So did Mr. Christian become the most human human? You'll need to read the book to find out, but in a way it doesn't matter. His own narrative for the most part stays in the background, allowing ideas to occupy center stage. The author's real battle was an existential one on behalf of all humankind. Any old computer can keep score; only humans can rate the quality of the game. Mr. Christian thinks that seeing a computer pass the Turing Test, "and the reality check to follow, might do us a world of good."

The recent victory of IBM's Watson supercomputer over a pair of "Jeopardy" champions suggests that he may be right. Watson showed an unprecedented ability to understand certain complexities of ambiguity and context. Following Mr. Christian's advice, we should not see this victory as a threat but as a chance to learn even more about who we are. Every technology that seems to dehumanize us is an opportunity to rehumanize ourselves.

 Mr. Baggini is editor in chief of The Philosophers' Magazine and the author of "The Ego Trick" (Granta). 